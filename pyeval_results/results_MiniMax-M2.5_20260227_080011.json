[
  {
    "id": "algo_001",
    "category": "algorithms",
    "difficulty": "easy",
    "title": "Binary Search",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "algo_002",
    "category": "algorithms",
    "difficulty": "easy",
    "title": "Bubble Sort",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "algo_003",
    "category": "algorithms",
    "difficulty": "medium",
    "title": "Merge Sort",
    "passed": true,
    "error": null,
    "generated_code": "def merge_sort(arr: list[int]) -> list[int]:\n    \"\"\"Sort a list of integers in ascending order using merge sort.\n\n    Args:\n        arr: A list of integers to sort.\n\n    Returns:\n        A new sorted list. The original list must not be modified.\n    \"\"\"\n    if len(arr) <= 1:\n        return list(arr)\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\n\ndef merge(left: list[int], right: list[int]) -> list[int]:\n    \"\"\"Merge two sorted lists into one sorted list.\"\"\"\n    result = []\n    i = j = 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    \n    return result",
    "stdout": "",
    "stderr": "...........\n----------------------------------------------------------------------\nRan 11 tests in 0.002s\n\nOK\n",
    "attempts": 3,
    "successful_attempt": 3,
    "score_weight": 0.3
  },
  {
    "id": "algo_004",
    "category": "algorithms",
    "difficulty": "medium",
    "title": "Longest Common Subsequence",
    "passed": false,
    "error": "API error: HTTP Error 500: Internal Server Error",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "algo_005",
    "category": "algorithms",
    "difficulty": "medium",
    "title": "Valid Parentheses",
    "passed": true,
    "error": null,
    "generated_code": "def valid_parentheses(s: str) -> bool:\n    \"\"\"Check if a string of brackets is valid.\n\n    A string is valid if:\n    - Open brackets are closed by the same type of brackets.\n    - Open brackets are closed in the correct order.\n    - Every close bracket has a corresponding open bracket of the same type.\n\n    Supported bracket types: (), [], {}\n\n    Args:\n        s: A string containing only the characters '(', ')', '[', ']', '{', '}'.\n\n    Returns:\n        True if the string is valid, False otherwise.\n    \"\"\"\n    stack = []\n    bracket_map = {')': '(', ']': '[', '}': '{'}\n    opening_brackets = set('([{')\n    \n    for char in s:\n        if char in opening_brackets:\n            stack.append(char)\n        elif char in bracket_map:\n            if not stack or stack[-1] != bracket_map[char]:\n                return False\n            stack.pop()\n    \n    return len(stack) == 0",
    "stdout": "",
    "stderr": ".............\n----------------------------------------------------------------------\nRan 13 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "algo_006",
    "category": "algorithms",
    "difficulty": "hard",
    "title": "0/1 Knapsack",
    "passed": true,
    "error": null,
    "generated_code": "def knapsack_01(weights: list[int], values: list[int], capacity: int) -> int:\n    \"\"\"Solve the 0/1 knapsack problem.\n\n    Given a set of items, each with a weight and a value, determine the\n    maximum total value that can be achieved by selecting items such that\n    the total weight does not exceed the given capacity. Each item can\n    either be included or excluded (no fractions).\n\n    Args:\n        weights: A list of positive integer weights for each item.\n        values: A list of positive integer values for each item.\n        capacity: The maximum total weight the knapsack can hold (non-negative integer).\n\n    Returns:\n        The maximum total value achievable within the weight capacity.\n    \"\"\"\n    n = len(weights)\n    if n == 0 or capacity == 0:\n        return 0\n    \n    # Create a 2D DP table where dp[i][w] represents the maximum value\n    # achievable using the first i items with a capacity of w\n    dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n    \n    # Fill the DP table\n    for i in range(1, n + 1):\n        for w in range(capacity + 1):\n            # Option 1: Don't include item i-1\n            dp[i][w] = dp[i - 1][w]\n            \n            # Option 2: Include item i-1 if it fits\n            if weights[i - 1] <= w:\n                dp[i][w] = max(dp[i][w], values[i - 1] + dp[i - 1][w - weights[i - 1]])\n    \n    return dp[n][capacity]",
    "stdout": "",
    "stderr": "...........\n----------------------------------------------------------------------\nRan 11 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "algo_007",
    "category": "algorithms",
    "difficulty": "hard",
    "title": "Topological Sort",
    "passed": true,
    "error": null,
    "generated_code": "def topological_sort(graph: dict[str, list[str]]) -> list[str]:\n    \"\"\"Return a topological ordering of a directed acyclic graph (DAG).\n\n    Args:\n        graph: An adjacency list representation of a directed graph.\n               Keys are node names (strings), values are lists of nodes\n               that the key node has edges TO. For example,\n               {'a': ['b', 'c']} means edges a->b and a->c.\n               All nodes in the graph appear as keys (even if they\n               have no outgoing edges).\n\n    Returns:\n        A list of node names in a valid topological order. If the graph\n        contains a cycle, return an empty list.\n    \"\"\"\n    from collections import deque\n    \n    # Calculate in-degree for each node\n    in_degree = {node: 0 for node in graph}\n    for node in graph:\n        for neighbor in graph[node]:\n            in_degree[neighbor] += 1\n    \n    # Initialize queue with nodes that have no incoming edges\n    queue = deque([node for node in graph if in_degree[node] == 0])\n    result = []\n    \n    while queue:\n        node = queue.popleft()\n        result.append(node)\n        \n        for neighbor in graph[node]:\n            in_degree[neighbor] -= 1\n            if in_degree[neighbor] == 0:\n                queue.append(neighbor)\n    \n    # If we processed all nodes, return the result; otherwise, there's a cycle\n    if len(result) == len(graph):\n        return result\n    return []",
    "stdout": "",
    "stderr": "...........\n----------------------------------------------------------------------\nRan 11 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "bs_001",
    "category": "basic_syntax",
    "difficulty": "easy",
    "title": "FizzBuzz",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "bs_002",
    "category": "basic_syntax",
    "difficulty": "easy",
    "title": "Swap Variables",
    "passed": false,
    "error": "API error: HTTP Error 500: Internal Server Error",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "bs_003",
    "category": "basic_syntax",
    "difficulty": "easy",
    "title": "Number to Words",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "bs_004",
    "category": "basic_syntax",
    "difficulty": "medium",
    "title": "Flatten Nested List",
    "passed": true,
    "error": null,
    "generated_code": "def flatten_nested(lst: list) -> list:\n    \"\"\"\n    Flatten an arbitrarily nested list into a single flat list.\n    The order of elements should be preserved (depth-first, left-to-right).\n    Non-list elements should be kept as-is.\n\n    Examples:\n        flatten_nested([1, [2, 3], [4, [5, 6]]]) -> [1, 2, 3, 4, 5, 6]\n        flatten_nested([1, [2, [3, [4, [5]]]]]) -> [1, 2, 3, 4, 5]\n        flatten_nested([]) -> []\n        flatten_nested([1, 'hello', [2, [True, None]]]) -> [1, 'hello', 2, True, None]\n    \"\"\"\n    result = []\n    for element in lst:\n        if isinstance(element, list):\n            result.extend(flatten_nested(element))\n        else:\n            result.append(element)\n    return result",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "bs_005",
    "category": "basic_syntax",
    "difficulty": "hard",
    "title": "Matrix Spiral Order",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "con_001",
    "category": "concurrency",
    "difficulty": "easy",
    "title": "Thread-Safe Counter",
    "passed": true,
    "error": null,
    "generated_code": "import threading\n\nclass ThreadSafeCounter:\n    \"\"\"\n    A thread-safe counter that can be safely incremented and decremented\n    from multiple threads simultaneously.\n\n    Methods:\n        __init__(self, initial=0): Initialize the counter with an optional\n            starting value (default 0).\n        increment(self): Atomically increase the counter by 1.\n        decrement(self): Atomically decrease the counter by 1.\n        get_value(self): Return the current counter value.\n\n    The counter must use threading.Lock to ensure thread safety.\n\n    Examples:\n        counter = ThreadSafeCounter()\n        counter.increment()\n        counter.increment()\n        counter.get_value()  # -> 2\n        counter.decrement()\n        counter.get_value()  # -> 1\n\n        counter = ThreadSafeCounter(10)\n        counter.get_value()  # -> 10\n    \"\"\"\n    \n    def __init__(self, initial=0):\n        self._value = initial\n        self._lock = threading.Lock()\n    \n    def increment(self):\n        with self._lock:\n            self._value += 1\n    \n    def decrement(self):\n        with self._lock:\n            self._value -= 1\n    \n    def get_value(self):\n        with self._lock:\n            return self._value",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.240s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "con_002",
    "category": "concurrency",
    "difficulty": "medium",
    "title": "Parallel Map",
    "passed": true,
    "error": null,
    "generated_code": "from concurrent.futures import ThreadPoolExecutor\n\ndef parallel_map(func, items: list, max_workers: int = 4) -> list:\n    \"\"\"\n    Apply a function to each item in a list using parallel execution with\n    a thread pool. Return the results in the same order as the input items.\n\n    Args:\n        func: A callable to apply to each item.\n        items: A list of items to process.\n        max_workers: Maximum number of threads to use (default 4).\n\n    Returns:\n        A list of results in the same order as the input.\n\n    Examples:\n        parallel_map(lambda x: x ** 2, [1, 2, 3, 4])  # -> [1, 4, 9, 16]        parallel_map(str.upper, [\"hello\", \"world\"])  # -> [\"HELLO\", \"WORLD\"]\n        parallel_map(lambda x: x + 1, [], max_workers=2)  # -> []\n    \"\"\"\n    if not items:\n        return []\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(executor.map(func, items))\n    \n    return results",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.115s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "con_003",
    "category": "concurrency",
    "difficulty": "medium",
    "title": "Producer Consumer",
    "passed": true,
    "error": null,
    "generated_code": "import threading\nimport queue\n\ndef producer_consumer(producers: list, consumers: list, queue_size: int = 10) -> list:\n    \"\"\"\n    Implement the producer-consumer pattern using threading and queue.Queue.\n\n    Args:\n        producers: A list of callables. Each producer callable, when called,\n            returns a list of items to be placed on the queue.        consumers: A list of callables. Each consumer callable takes a single\n            item from the queue and returns a processed result.\n        queue_size: Maximum size of the shared queue (default 10).\n\n    Behavior:\n        - Create a bounded Queue with the given queue_size.\n        - Start one thread per consumer FIRST. Each consumer thread loops:\n          gets an item from the queue, and if it's None (sentinel), stops.\n          Otherwise, calls its consumer callable on the item and collects\n          the result.\n        - Start one thread per producer. Each producer thread calls its callable\n          to get items, then puts each item on the queue.\n        - Wait for all producer threads to finish.\n        - Put one sentinel None per consumer on the queue.\n        - Wait for all consumer threads to finish.\n        - Return ALL consumed (processed) results as a single flat list.\n          The order of results does not need to match input order.\n\n    Examples:\n        results = producer_consumer(\n            producers=[lambda: [1, 2, 3], lambda: [4, 5]],\n            consumers=[lambda x: x * 2],\n            queue_size=5\n        )\n        sorted(results)  # -> [2, 4, 6, 8, 10]\n    \"\"\"\n    shared_queue = queue.Queue(maxsize=queue_size)\n    results = []\n    results_lock = threading.Lock()\n    \n    def consumer_wrapper(consumer_func):\n        while True:\n            item = shared_queue.get()\n            if item is None:\n                shared_queue.task_done()\n                break\n            result = consumer_func(item)\n            with results_lock:\n                results.append(result)\n            shared_queue.task_done()\n    \n    def producer_wrapper(producer_func):\n        items = producer_func()\n        for item in items:\n            shared_queue.put(item)\n    \n    # Start consumer threads FIRST\n    consumer_threads = []\n    for consumer in consumers:\n        t = threading.Thread(target=consumer_wrapper, args=(consumer,))\n        t.start()\n        consumer_threads.append(t)\n    \n    # Start producer threads\n    producer_threads = []\n    for producer in producers:\n        t = threading.Thread(target=producer_wrapper, args=(producer,))\n        t.start()\n        producer_threads.append(t)\n    \n    # Wait for all producer threads to finish\n    for t in producer_threads:\n        t.join()\n    \n    # Put one sentinel None per consumer on the queue\n    for _ in range(len(consumers)):\n        shared_queue.put(None)\n    \n    # Wait for all consumer threads to finish\n    for t in consumer_threads:\n        t.join()\n    \n    return results",
    "stdout": "",
    "stderr": ".........\n----------------------------------------------------------------------\nRan 9 tests in 0.009s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "con_004",
    "category": "concurrency",
    "difficulty": "hard",
    "title": "Async Gather with Timeout",
    "passed": true,
    "error": null,
    "generated_code": "import asyncio\n\nasync def async_gather_results(async_callables: list, timeout: float = None) -> list:\n    \"\"\"\n    Run a list of async callables (coroutine functions) concurrently and\n    return their results.\n\n    Args:\n        async_callables: A list of async callables (coroutine functions that\n            take no arguments). Each one, when called, returns a coroutine.\n        timeout: Optional timeout in seconds. If provided and the total\n            execution exceeds this duration, raise asyncio.TimeoutError.\n            If None, no timeout is applied.\n\n    Returns:\n        A list of results in the same order as the input callables.\n\n    Behavior:\n        - Call each async callable to create a coroutine.\n        - Run all coroutines concurrently using asyncio.gather.\n        - If timeout is specified, use asyncio.wait_for to enforce the timeout\n          around the gather call.\n        - Return the list of results.\n\n    Examples:\n        async def make_value(v):\n            await asyncio.sleep(0.01)\n            return v\n\n        results = await async_gather_results([\n            lambda: make_value(1),\n            lambda: make_value(2),\n            lambda: make_value(3)\n        ])\n        # results -> [1, 2, 3]\n\n        # With timeout (this would raise asyncio.TimeoutError if too slow):\n        results = await async_gather_results(\n            [lambda: make_value(42)],\n            timeout=5.0\n        )\n        # results -> [42]\n    \"\"\"\n    # Create coroutines by calling each async callable\n    coroutines = [callable() for callable in async_callables]\n    \n    # Run all coroutines concurrently\n    if timeout is not None:\n        # Use wait_for to apply timeout\n        results = await asyncio.wait_for(\n            asyncio.gather(*coroutines),\n            timeout=timeout\n        )\n    else:\n        results = await asyncio.gather(*coroutines)\n    \n    return results",
    "stdout": "",
    "stderr": "/tmp/tmp5ykal53x.py:68: DeprecationWarning: There is no current event loop\n  self.loop = asyncio.get_event_loop()\n...........\n----------------------------------------------------------------------\nRan 11 tests in 0.274s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "ds_001",
    "category": "data_structures",
    "difficulty": "easy",
    "title": "Two Sum",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "ds_002",
    "category": "data_structures",
    "difficulty": "easy",
    "title": "Reverse Linked List",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "ds_003",
    "category": "data_structures",
    "difficulty": "medium",
    "title": "LRU Cache",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "ds_004",
    "category": "data_structures",
    "difficulty": "medium",
    "title": "Group Anagrams",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "ds_005",
    "category": "data_structures",
    "difficulty": "hard",
    "title": "Merge K Sorted Lists",
    "passed": false,
    "error": "API error: HTTP Error 429: Too Many Requests",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "exc_001",
    "category": "exceptions",
    "difficulty": "easy",
    "title": "Safe Divide",
    "passed": true,
    "error": null,
    "generated_code": "def safe_divide(a, b):\n    \"\"\"Divide a by b safely.\n\n    Args:\n        a: The numerator.\n        b: The denominator.\n\n    Returns:\n        The result of a / b, or None if b is zero.\n\n    Raises:\n        TypeError: If either a or b is not a number (int or float).\n    \"\"\"\n    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n        raise TypeError(\"Both a and b must be numbers (int or float)\")\n    \n    if b == 0:\n        return None\n    \n    return a / b",
    "stdout": "",
    "stderr": ".............\n----------------------------------------------------------------------\nRan 13 tests in 0.000s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "exc_002",
    "category": "exceptions",
    "difficulty": "medium",
    "title": "Retry Decorator",
    "passed": true,
    "error": null,
    "generated_code": "import time\nimport functools\n\n\ndef retry(max_attempts=3, exceptions=(Exception,), delay=0):\n    \"\"\"A decorator that retries a function on failure.\n\n    Args:\n        max_attempts (int): Maximum number of attempts (including the first call).\n            Must be >= 1.\n        exceptions (tuple): A tuple of exception types to catch and retry on.\n            Any other exception types should propagate immediately.\n        delay (float): Seconds to wait between retries. Defaults to 0.\n\n    Returns:\n        A decorator that wraps the target function with retry logic.\n\n    Behavior:\n        - Call the decorated function. If it succeeds, return its result.\n        - If it raises one of the specified exception types and attempts remain,\n          wait `delay` seconds, then retry.\n        - If all attempts are exhausted, raise the last exception.\n        - The decorator should preserve the original function's name and docstring\n          (use functools.wraps).\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            last_exception = None\n            \n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except exceptions as e:\n                    last_exception = e\n                    if attempt < max_attempts - 1:\n                        if delay > 0:\n                            time.sleep(delay)\n            \n            raise last_exception\n        \n        return wrapper\n    return decorator",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.101s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "exc_003",
    "category": "exceptions",
    "difficulty": "hard",
    "title": "Custom Exception Hierarchy and Schema Validation",
    "passed": false,
    "error": "API request timed out",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "fio_001",
    "category": "file_io",
    "difficulty": "easy",
    "title": "Read CSV Data",
    "passed": true,
    "error": null,
    "generated_code": "import csv\nimport io\n\ndef read_csv_data(csv_string: str) -> list:\n    \"\"\"\n    Parse a CSV-formatted string into a list of dictionaries.\n\n    The first row of the CSV string contains the headers, which become\n    the dictionary keys. Each subsequent row becomes a dictionary with\n    values mapped to the corresponding headers.\n\n    Use the csv module for parsing. Handle quoted fields correctly.\n\n    Args:\n        csv_string: A string containing CSV-formatted data\n\n    Returns:\n        A list of dictionaries, one per data row\n\n    Examples:\n        read_csv_data('name,age\\nAlice,30\\nBob,25')\n        -> [{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n\n        read_csv_data('a,b\\n1,2')\n        -> [{'a': '1', 'b': '2'}]\n    \"\"\"\n    # Create a StringIO object from the csv_string to treat it as a file\n    csv_file = io.StringIO(csv_string)\n    \n    # Use DictReader to parse the CSV - it automatically uses the first row\n    # as headers and handles quoted fields correctly\n    reader = csv.DictReader(csv_file)\n    \n    # Convert the reader to a list of dictionaries and return\n    return list(reader)",
    "stdout": "",
    "stderr": "........\n----------------------------------------------------------------------\nRan 8 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fio_002",
    "category": "file_io",
    "difficulty": "medium",
    "title": "Merge JSON Files",
    "passed": true,
    "error": null,
    "generated_code": "import json\n\ndef merge_json_files(json_strings: list) -> dict:\n    \"\"\"\n    Merge a list of JSON strings into a single dictionary.\n\n    Each JSON string represents a dictionary. Merge them left to right so\n    that later values override earlier ones for the same keys. For nested\n    dictionaries, perform a deep merge: if both the existing and new values\n    for a key are dicts, merge them recursively instead of replacing.\n\n    Non-dict values always override (even if the existing value is a dict).\n\n    Args:\n        json_strings: A list of strings, each a valid JSON object\n\n    Returns:\n        A single merged dictionary\n\n    Examples:\n        merge_json_files(['{\"a\": 1}', '{\"b\": 2}'])\n        -> {'a': 1, 'b': 2}\n\n        merge_json_files(['{\"a\": 1}', '{\"a\": 2}'])\n        -> {'a': 2}\n\n        merge_json_files(['{\"x\": {\"a\": 1, \"b\": 2}}', '{\"x\": {\"b\": 3, \"c\": 4}}'])\n        -> {'x': {'a': 1, 'b': 3, 'c': 4}}\n    \"\"\"\n    result = {}\n    \n    for json_str in json_strings:\n        data = json.loads(json_str)\n        result = _deep_merge(result, data)\n    \n    return result\n\n\ndef _deep_merge(existing: dict, new: dict) -> dict:\n    \"\"\"\n    Recursively merge new dictionary into existing dictionary.\n    Non-dict values in new override values in existing.\n    \"\"\"\n    for key, value in new.items():\n        if key in existing and isinstance(existing[key], dict) and isinstance(value, dict):\n            # Both values are dicts, merge recursively\n            existing[key] = _deep_merge(existing[key], value)\n        else:\n            # Non-dict value overrides (or key doesn't exist)\n            existing[key] = value\n    return existing",
    "stdout": "",
    "stderr": "...........\n----------------------------------------------------------------------\nRan 11 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fio_003",
    "category": "file_io",
    "difficulty": "hard",
    "title": "Log Parser",
    "passed": true,
    "error": null,
    "generated_code": "import re\n\ndef log_parser(log_lines: list) -> dict:\n    # Regular expression to parse the log lines\n    pattern = r'\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] (DEBUG|INFO|WARNING|ERROR|CRITICAL): (.*)'\n    \n    counts = {}\n    errors = []\n    timestamps = []\n    \n    for line in log_lines:\n        match = re.match(pattern, line)\n        if match:\n            timestamp, level, message = match.groups()\n            timestamps.append(timestamp)\n            counts[level] = counts.get(level, 0) + 1\n            \n            if level in ('ERROR', 'CRITICAL'):\n                errors.append(message)\n    \n    # Determine timestamp range\n    if timestamps:\n        timestamp_range = (min(timestamps), max(timestamps))\n    else:\n        timestamp_range = None\n    \n    return {\n        'counts': counts,\n        'errors': errors,\n        'timestamp_range': timestamp_range\n    }",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fn_001",
    "category": "functional",
    "difficulty": "easy",
    "title": "Apply Pipeline",
    "passed": true,
    "error": null,
    "generated_code": "def apply_pipeline(value, functions: list):\n    \"\"\"\n    Given an initial value and a list of single-argument functions,\n    apply each function in sequence (left to right) to the value,\n    passing the result of each function as input to the next.\n    Return the final result.\n\n    If the functions list is empty, return the original value.\n\n    Examples:\n        apply_pipeline(5, [lambda x: x + 1, lambda x: x * 2]) -> 12\n        apply_pipeline(\"hello\", [str.upper, lambda s: s + \"!\"]) -> \"HELLO!\"\n        apply_pipeline(10, []) -> 10\n        apply_pipeline(-3, [abs, lambda x: x ** 2]) -> 9\n    \"\"\"\n    result = value\n    for func in functions:\n        result = func(result)\n    return result",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fn_002",
    "category": "functional",
    "difficulty": "medium",
    "title": "Memoize Decorator",
    "passed": true,
    "error": null,
    "generated_code": "def memoize(func):\n    \"\"\"\n    Implement a memoize decorator that caches the results of function calls.\n    If the function is called again with the same positional arguments,\n    return the cached result instead of recomputing.\n\n    Assume all arguments are hashable (can be used as dict keys via tuple).\n    Only positional arguments need to be supported (no kwargs).\n\n    The decorated function should also have a .cache attribute that is\n    the dictionary used for caching (mapping argument tuples to results).\n\n    Examples:\n        @memoize\n        def add(a, b):\n            return a + b\n\n        add(1, 2)  # computes and caches\n        add(1, 2)  # returns cached result\n        add.cache  # {(1, 2): 3}\n    \"\"\"\n    cache = {}\n    \n    def wrapper(*args):\n        if args in cache:\n            return cache[args]\n        result = func(*args)\n        cache[args] = result\n        return result\n    \n    wrapper.cache = cache\n    return wrapper",
    "stdout": "",
    "stderr": "........\n----------------------------------------------------------------------\nRan 8 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fn_003",
    "category": "functional",
    "difficulty": "medium",
    "title": "Group By",
    "passed": true,
    "error": null,
    "generated_code": "def group_by(items: list, key_func) -> dict:\n    \"\"\"\n    Group elements of a list by the result of applying key_func to each element.\n    Return a dictionary where keys are the results of key_func and values are\n    lists of items that produced that key, in their original order.\n\n    Examples:\n        group_by([1, 2, 3, 4, 5, 6], lambda x: x % 2 == 0)\n        # -> {False: [1, 3, 5], True: [2, 4, 6]}\n\n        group_by([\"apple\", \"banana\", \"avocado\", \"blueberry\"], lambda s: s[0])\n        # -> {\"a\": [\"apple\", \"avocado\"], \"b\": [\"banana\", \"blueberry\"]}\n\n        group_by([], lambda x: x)\n        # -> {}\n\n        group_by([1, 2, 3, 4, 5], lambda x: \"even\" if x % 2 == 0 else \"odd\")\n        # -> {\"odd\": [1, 3, 5], \"even\": [2, 4]}\n    \"\"\"\n    result = {}\n    for item in items:\n        key = key_func(item)\n        if key not in result:\n            result[key] = []\n        result[key].append(item)\n    return result",
    "stdout": "",
    "stderr": "..........\n----------------------------------------------------------------------\nRan 10 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "fn_004",
    "category": "functional",
    "difficulty": "hard",
    "title": "Lazy Evaluation",
    "passed": true,
    "error": null,
    "generated_code": "class Lazy:\n    \"\"\"\n    A lazy evaluation class that wraps an iterable and supports chaining\n    map and filter operations. Operations are NOT executed until\n    .evaluate() is called.\n\n    Methods:\n        __init__(self, iterable): Store the iterable and initialize an empty\n            list of pending operations.\n        map(self, func): Register a map operation. Returns self for chaining.\n        filter(self, predicate): Register a filter operation. Returns self for chaining.\n        evaluate(self): Execute all registered operations in order on the\n            iterable and return the result as a list.\n\n    The Lazy object should be reusable - after calling evaluate(), the\n    pending operations are cleared but the original iterable is preserved,\n    so new chains can be built.\n\n    Examples:\n        Lazy([1, 2, 3, 4, 5]).filter(lambda x: x % 2 == 0).map(lambda x: x * 10).evaluate() # -> [20, 40]\n\n        lazy = Lazy(range(10))\n        lazy.map(lambda x: x ** 2).filter(lambda x: x > 10).evaluate()\n        # -> [16, 25, 36, 49, 64, 81]\n\n        Lazy([]).evaluate()  # -> []\n    \"\"\"\n    \n    def __init__(self, iterable):\n        self.iterable = list(iterable)\n        self.operations = []\n    \n    def map(self, func):\n        self.operations.append(('map', func))\n        return self\n    \n    def filter(self, predicate):\n        self.operations.append(('filter', predicate))\n        return self\n    \n    def evaluate(self):\n        result = self.iterable.copy()\n        for op_type, op_func in self.operations:\n            if op_type == 'map':\n                result = [op_func(x) for x in result]\n            elif op_type == 'filter':\n                result = [x for x in result if op_func(x)]\n        self.operations = []\n        return result",
    "stdout": "",
    "stderr": "..............\n----------------------------------------------------------------------\nRan 14 tests in 0.001s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "oop_001",
    "category": "oop",
    "difficulty": "easy",
    "title": "Stack Class",
    "passed": true,
    "error": null,
    "generated_code": "class Stack:\n    \"\"\"A stack data structure with standard operations.\n\n    Methods:\n        push(item): Add an item to the top of the stack.\n        pop(): Remove and return the top item. Raise IndexError if empty.\n        peek(): Return the top item without removing it. Raise IndexError if empty.\n        is_empty(): Return True if the stack is empty, False otherwise.\n        size(): Return the number of items in the stack.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty stack.\"\"\"\n        self._items = []\n\n    def push(self, item):\n        \"\"\"Add an item to the top of the stack.\"\"\"\n        self._items.append(item)\n\n    def pop(self):\n        \"\"\"Remove and return the top item.\n\n        Raises:\n            IndexError: If the stack is empty.\n        \"\"\"\n        if self.is_empty():\n            raise IndexError(\"pop from empty stack\")\n        return self._items.pop()\n\n    def peek(self):\n        \"\"\"Return the top item without removing it.\n\n        Raises:\n            IndexError: If the stack is empty.\n        \"\"\"\n        if self.is_empty():\n            raise IndexError(\"peek from empty stack\")\n        return self._items[-1]\n\n    def is_empty(self):\n        \"\"\"Return True if the stack is empty, False otherwise.\"\"\"\n        return len(self._items) == 0\n\n    def size(self):\n        \"\"\"Return the number of items in the stack.\"\"\"\n        return len(self._items)",
    "stdout": "",
    "stderr": "........\n----------------------------------------------------------------------\nRan 8 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "oop_002",
    "category": "oop",
    "difficulty": "medium",
    "title": "Shape Hierarchy with Abstract Base Class",
    "passed": true,
    "error": null,
    "generated_code": "from abc import ABC, abstractmethod\nimport math\n\n\nclass Shape(ABC):\n    \"\"\"Abstract base class for shapes.\n\n    Abstract Methods:\n        area() -> float: Return the area of the shape.\n        perimeter() -> float: Return the perimeter of the shape.\n    \"\"\"\n\n    @abstractmethod\n    def area(self) -> float:\n        pass\n\n    @abstractmethod\n    def perimeter(self) -> float:\n        pass\n\n\nclass Circle(Shape):\n    \"\"\"A circle defined by its radius.\n\n    Args:\n        radius (float): The radius of the circle. Must be positive.\n            Raise ValueError if radius <= 0.\n    \"\"\"\n\n    def __init__(self, radius: float):\n        if radius <= 0:\n            raise ValueError(\"Radius must be positive\")\n        self.radius = radius\n\n    def area(self) -> float:\n        return math.pi * self.radius ** 2\n\n    def perimeter(self) -> float:\n        return 2 * math.pi * self.radius\n\n\nclass Rectangle(Shape):\n    \"\"\"A rectangle defined by width and height.\n\n    Args:\n        width (float): The width of the rectangle. Must be positive.\n        height (float): The height of the rectangle. Must be positive.\n            Raise ValueError if width or height <= 0.\n    \"\"\"\n\n    def __init__(self, width: float, height: float):\n        if width <= 0 or height <= 0:\n            raise ValueError(\"Width and height must be positive\")\n        self.width = width\n        self.height = height\n\n    def area(self) -> float:\n        return self.width * self.height\n\n    def perimeter(self) -> float:\n        return 2 * (self.width + self.height)\n\n\ndef calculate_total_area(shapes):\n    \"\"\"Return the sum of areas of all shapes in the list.\n\n    Args:\n        shapes: A list of Shape instances.\n\n    Returns:\n        float: The total area.\n    \"\"\"\n    return sum(shape.area() for shape in shapes)",
    "stdout": "",
    "stderr": "...............\n----------------------------------------------------------------------\nRan 15 tests in 0.001s\n\nOK\n",
    "attempts": 3,
    "successful_attempt": 3,
    "score_weight": 0.3
  },
  {
    "id": "oop_003",
    "category": "oop",
    "difficulty": "medium",
    "title": "BankAccount with Transaction History",
    "passed": true,
    "error": null,
    "generated_code": "class BankAccount:\n    \"\"\"A bank account with deposit, withdraw, transfer, and transaction history.\n\n    Constructor:\n        __init__(self, owner: str, initial_balance: float = 0.0)\n            Store owner as a public attribute (self.owner).\n            Store balance internally; expose via read-only property.\n            Initialize an empty transaction history list.\n            Raise ValueError if initial_balance < 0.\n            Do NOT record the initial balance as a transaction.\n\n    Public Attributes:\n        owner (str): The name of the account owner (directly accessible).\n\n    Properties:\n        balance (float): The current balance (read-only property).\n\n    Methods:\n        deposit(amount) -> None:\n            Add amount to balance. Raise ValueError if amount <= 0.\n            Record transaction as ('deposit', amount) in history.\n\n        withdraw(amount) -> None:\n            Subtract amount from balance.\n            Raise ValueError if amount <= 0.\n            Raise ValueError if insufficient funds.\n            Record transaction as ('withdraw', amount) in history.\n\n        transfer_to(other_account, amount) -> None:\n            Withdraw amount from this account and deposit into other_account.\n            Raise ValueError if amount <= 0.\n            Raise ValueError if insufficient funds.\n            Record transaction as ('transfer_out', amount) in this account's history.\n            Record transaction as ('transfer_in', amount) in other account's history.\n\n        get_history() -> list:\n            Return a copy of all transaction tuples in chronological order.\n    \"\"\"\n\n    def __init__(self, owner: str, initial_balance: float = 0.0):\n        if initial_balance < 0:\n            raise ValueError(\"Initial balance cannot be negative\")\n        self.owner = owner\n        self._balance = initial_balance\n        self._history = []\n\n    @property\n    def balance(self) -> float:\n        return self._balance\n\n    def deposit(self, amount: float) -> None:\n        if amount <= 0:\n            raise ValueError(\"Deposit amount must be positive\")\n        self._balance += amount\n        self._history.append(('deposit', amount))\n\n    def withdraw(self, amount: float) -> None:\n        if amount <= 0:\n            raise ValueError(\"Withdrawal amount must be positive\")\n        if amount > self._balance:\n            raise ValueError(\"Insufficient funds\")\n        self._balance -= amount\n        self._history.append(('withdraw', amount))\n\n    def transfer_to(self, other_account: 'BankAccount', amount: float) -> None:\n        if amount <= 0:\n            raise ValueError(\"Transfer amount must be positive\")\n        if amount > self._balance:\n            raise ValueError(\"Insufficient funds\")\n        self._balance -= amount\n        other_account._balance += amount\n        self._history.append(('transfer_out', amount))\n        other_account._history.append(('transfer_in', amount))\n\n    def get_history(self) -> list:\n        return self._history.copy()",
    "stdout": "",
    "stderr": ".................\n----------------------------------------------------------------------\nRan 17 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "oop_004",
    "category": "oop",
    "difficulty": "hard",
    "title": "EventEmitter - Observer Pattern",
    "passed": true,
    "error": null,
    "generated_code": "class EventEmitter:\n    \"\"\"An event emitter implementing the observer pattern.\n\n    Methods:\n        on(event: str, callback: callable) -> None:\n            Register a callback for the given event.\n            The same callback can be registered multiple times for the same event;\n            each registration counts separately.\n\n        off(event: str, callback: callable) -> None:\n            Remove one registration of callback for the given event.\n            If the callback is registered multiple times, only remove the first one.\n            If callback is not registered for this event, do nothing (no error).\n\n        emit(event: str, *args, **kwargs) -> None:\n            Call all registered callbacks for the event with the given arguments.\n            Callbacks are called in the order they were registered.\n            If no callbacks are registered for the event, do nothing.\n\n        once(event: str, callback: callable) -> None:\n            Register a callback that is automatically removed after it fires once.\n\n        listener_count(event: str) -> int:\n            Return the number of listeners registered for the given event.\n    \"\"\"\n\n    def __init__(self):\n        self._events = {}  # event_name -> list of callbacks\n\n    def on(self, event: str, callback: callable) -> None:\n        \"\"\"Register a callback for the given event.\"\"\"\n        if event not in self._events:\n            self._events[event] = []\n        self._events[event].append(callback)\n\n    def off(self, event: str, callback: callable) -> None:\n        \"\"\"Remove one registration of callback for the given event.\"\"\"\n        if event in self._events:\n            try:\n                self._events[event].remove(callback)\n            except ValueError:\n                pass  # callback not registered, do nothing\n\n    def emit(self, event: str, *args, **kwargs) -> None:\n        \"\"\"Call all registered callbacks for the event with the given arguments.\"\"\"\n        if event in self._events:\n            # Iterate over a copy to handle callbacks that modify the list during iteration\n            for callback in self._events[event][:]:\n                callback(*args, **kwargs)\n\n    def once(self, event: str, callback: callable) -> None:\n        \"\"\"Register a callback that is automatically removed after it fires once.\"\"\"\n        def wrapper(*args, **kwargs):\n            callback(*args, **kwargs)\n            self.off(event, wrapper)\n        self.on(event, wrapper)\n\n    def listener_count(self, event: str) -> int:\n        \"\"\"Return the number of listeners registered for the given event.\"\"\"\n        return len(self._events.get(event, []))",
    "stdout": "",
    "stderr": "...............\n----------------------------------------------------------------------\nRan 15 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "oop_005",
    "category": "oop",
    "difficulty": "hard",
    "title": "ValidatedField Descriptor",
    "passed": true,
    "error": null,
    "generated_code": "class ValidatedField:\n    \"\"\"A descriptor that validates field values on assignment.\n\n    Constructor:\n        __init__(self, field_type, *, min_value=None, max_value=None, max_length=None)\n\n    Descriptor Protocol:\n        __set_name__(self, owner, name):\n            Store the field name. Use a private storage attribute like\n            '_validated_' + name on the instance to avoid conflicts.\n\n        __get__(self, obj, objtype=None):\n            If obj is None (class-level access), return the descriptor itself.\n            Otherwise return the stored value.\n            Raise AttributeError if the value has not been set yet.\n\n        __set__(self, obj, value):\n            Validate the value before storing:\n            1. Check isinstance(value, field_type). Raise TypeError if not.\n            2. If field_type is int or float and min_value is set, raise ValueError\n               if value < min_value.\n            3. If field_type is int or float and max_value is set, raise ValueError\n               if value > max_value.\n            4. If field_type is str and max_length is set, raise ValueError\n               if len(value) > max_length.\n    \"\"\"\n\n    def __init__(self, field_type, *, min_value=None, max_value=None, max_length=None):\n        self.field_type = field_type\n        self.min_value = min_value\n        self.max_value = max_value\n        self.max_length = max_length\n        self.name = None\n\n    def __set_name__(self, owner, name):\n        self.name = '_validated_' + name\n\n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        if not hasattr(obj, self.name):\n            raise AttributeError(f\"'{type(obj).__name__}' object has no attribute '{self.name[11:]}'\")\n        return getattr(obj, self.name)\n\n    def __set__(self, obj, value):\n        if not isinstance(value, self.field_type):\n            raise TypeError(f\"'{type(value).__name__}' is not an instance of '{self.field_type.__name__}'\")\n\n        if self.field_type in (int, float):\n            if self.min_value is not None and value < self.min_value:\n                raise ValueError(f\"Value must be >= {self.min_value}\")\n            if self.max_value is not None and value > self.max_value:\n                raise ValueError(f\"Value must be <= {self.max_value}\")\n\n        if self.field_type is str and self.max_length is not None and len(value) > self.max_length:\n            raise ValueError(f\"String length must be <= {self.max_length}\")\n\n        setattr(obj, self.name, value)\n\n\nclass Person:\n    \"\"\"A class using ValidatedField descriptors.\n\n    Class-level descriptor fields:\n        name = ValidatedField(str, max_length=50)\n        age = ValidatedField(int, min_value=0, max_value=200)\n        email = ValidatedField(str, max_length=100)\n\n    Constructor:\n        __init__(self, name: str, age: int, email: str)\n            Assign all three arguments to self (triggering descriptor validation).\n    \"\"\"\n\n    name = ValidatedField(str, max_length=50)\n    age = ValidatedField(int, min_value=0, max_value=200)\n    email = ValidatedField(str, max_length=100)\n\n    def __init__(self, name: str, age: int, email: str):\n        self.name = name\n        self.age = age\n        self.email = email",
    "stdout": "",
    "stderr": "..................\n----------------------------------------------------------------------\nRan 18 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "std_001",
    "category": "stdlib",
    "difficulty": "easy",
    "title": "Count Words",
    "passed": true,
    "error": null,
    "generated_code": "from collections import Counter\n\ndef count_words(text: str) -> dict[str, int]:\n    \"\"\"Count the frequency of each word in a string.\n\n    Words are separated by whitespace. Counting is case-sensitive\n    (i.e., 'Hello' and 'hello' are different words).\n\n    Args:\n        text: A string of words separated by whitespace.\n\n    Returns:\n        A dictionary mapping each word to the number of times it appears.\n    \"\"\"\n    words = text.split()\n    return dict(Counter(words))",
    "stdout": "",
    "stderr": ".........\n----------------------------------------------------------------------\nRan 9 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "std_002",
    "category": "stdlib",
    "difficulty": "easy",
    "title": "Parse Date",
    "passed": true,
    "error": null,
    "generated_code": "from datetime import datetime\n\ndef parse_date(date_str: str) -> str:\n    \"\"\"Parse a date string in 'YYYY-MM-DD' format and return the day of the week.\n\n    Args:\n        date_str: A date string in the format 'YYYY-MM-DD'.\n\n    Returns:\n        The day of the week as a full string, e.g. 'Monday', 'Tuesday', etc.\n    \"\"\"\n    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n    return date_obj.strftime('%A')",
    "stdout": "",
    "stderr": "...........\n----------------------------------------------------------------------\nRan 11 tests in 0.003s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "std_003",
    "category": "stdlib",
    "difficulty": "medium",
    "title": "Validate Email",
    "passed": false,
    "error": "API request timed out",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "std_004",
    "category": "stdlib",
    "difficulty": "medium",
    "title": "Cartesian Product Filter",
    "passed": true,
    "error": null,
    "generated_code": "from itertools import product\n\ndef cartesian_filter(lists: list[list[int]], threshold: int) -> list[tuple[int, ...]]:\n    \"\"\"Generate the cartesian product of multiple lists of integers and\n    filter to keep only tuples whose element sum exceeds a threshold.\n\n    Args:\n        lists: A list of lists of integers. The cartesian product is\n               computed across all provided lists.\n        threshold: An integer threshold. Only tuples whose sum is\n                   strictly greater than this value are included.\n\n    Returns:\n        A list of tuples (in the order produced by itertools.product)\n        where the sum of elements is strictly greater than the threshold.\n        Returns an empty list if lists is empty.\n    \"\"\"\n    if not lists:\n        return []\n    \n    result = []\n    for combo in product(*lists):\n        if sum(combo) > threshold:\n            result.append(combo)\n    \n    return result",
    "stdout": "",
    "stderr": "............\n----------------------------------------------------------------------\nRan 12 tests in 0.001s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "std_005",
    "category": "stdlib",
    "difficulty": "hard",
    "title": "Parallel Map",
    "passed": false,
    "error": "API error: HTTP Error 500: Internal Server Error",
    "generated_code": "",
    "stdout": "",
    "stderr": "",
    "attempts": 3,
    "successful_attempt": null,
    "score_weight": 0.0
  },
  {
    "id": "str_001",
    "category": "string_processing",
    "difficulty": "easy",
    "title": "Is Palindrome",
    "passed": true,
    "error": null,
    "generated_code": "import re\n\ndef is_palindrome(s: str) -> bool:\n    \"\"\"\n    Check if a string is a palindrome, ignoring case, spaces, and punctuation.\n\n    Only consider alphanumeric characters when determining if the string\n    is a palindrome.\n\n    Args:\n        s: The input string\n\n    Returns:\n        True if the string is a palindrome, False otherwise\n\n    Examples:\n        is_palindrome('racecar') -> True\n        is_palindrome('A man, a plan, a canal: Panama') -> True\n        is_palindrome('hello') -> False\n        is_palindrome('') -> True\n    \"\"\"\n    # Remove all non-alphanumeric characters and convert to lowercase\n    cleaned = re.sub(r'[^a-zA-Z0-9]', '', s).lower()\n    # Check if the cleaned string equals its reverse\n    return cleaned == cleaned[::-1]",
    "stdout": "",
    "stderr": ".............\n----------------------------------------------------------------------\nRan 13 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "str_002",
    "category": "string_processing",
    "difficulty": "easy",
    "title": "Caesar Cipher",
    "passed": true,
    "error": null,
    "generated_code": "def caesar_cipher(text: str, shift: int, mode: str = 'encrypt') -> str:\n    \"\"\"\n    Encrypt or decrypt text using a Caesar cipher.\n\n    Shift each letter by the given amount. Preserve case. Non-alphabetic\n    characters (spaces, punctuation, digits) are left unchanged.\n\n    For encryption, shift letters forward in the alphabet.\n    For decryption, shift letters backward.    The shift value can be any integer and will be normalized mod 26.\n\n    Args:\n        text: The input string\n        shift: Integer shift value\n        mode: 'encrypt' or 'decrypt'\n\n    Returns:\n        The encrypted or decrypted string\n\n    Examples:\n        caesar_cipher('Hello, World!', 3, 'encrypt') -> 'Khoor, Zruog!'\n        caesar_cipher('Khoor, Zruog!', 3, 'decrypt') -> 'Hello, World!'\n        caesar_cipher('abc', 1, 'encrypt') -> 'bcd'\n        caesar_cipher('xyz', 3, 'encrypt') -> 'abc'\n    \"\"\"\n    result = []\n    \n    # Normalize shift based on mode\n    if mode == 'decrypt':\n        shift = -shift\n    \n    # Normalize shift to be within 0-25\n    shift = shift % 26\n    \n    for char in text:\n        if char.isalpha():\n            # Determine the ASCII base (uppercase or lowercase)\n            base = ord('A') if char.isupper() else ord('a')\n            # Shift the character and wrap around using modulo\n            shifted = (ord(char) - base + shift) % 26\n            result.append(chr(base + shifted))\n        else:\n            # Non-alphabetic characters remain unchanged\n            result.append(char)\n    \n    return ''.join(result)",
    "stdout": "",
    "stderr": ".............\n----------------------------------------------------------------------\nRan 13 tests in 0.000s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  },
  {
    "id": "str_003",
    "category": "string_processing",
    "difficulty": "medium",
    "title": "Extract URLs",
    "passed": true,
    "error": null,
    "generated_code": "import re\n\ndef extract_urls(text: str) -> list:\n    \"\"\"\n    Extract all URLs from a text string.\n\n    Find all URLs that start with http:// or https:// followed by\n    one or more non-whitespace characters. URLs should not end with\n    trailing punctuation marks (period, comma, semicolon, exclamation\n    mark, question mark, closing parenthesis) that are likely part of\n    the surrounding text rather than the URL itself.\n\n    Args:\n        text: The input string that may contain URLs\n\n    Returns:\n        A list of URL strings found in the text, in order of appearance\n\n    Examples:\n        extract_urls('Visit https://example.com for more info')\n        -> ['https://example.com']\n\n        extract_urls('No URLs here')\n        -> []\n\n        extract_urls('Go to http://a.com and https://b.com/path')\n        -> ['http://a.com', 'https://b.com/path']\n    \"\"\"\n    # Pattern to match URLs starting with http:// or https://\n    # followed by one or more non-whitespace characters\n    pattern = r'https?://\\S+'\n    \n    # Find all potential URL matches\n    urls = re.findall(pattern, text)\n    \n    # Punctuation marks to strip from end of URLs\n    trailing_punctuation = '.,;:!?)}'\n    \n    # Clean URLs by removing trailing punctuation\n    cleaned_urls = []\n    for url in urls:\n        # Strip trailing punctuation characters\n        while url and url[-1] in trailing_punctuation:\n            url = url[:-1]\n        if url:\n            cleaned_urls.append(url)\n    \n    return cleaned_urls",
    "stdout": "",
    "stderr": ".............\n----------------------------------------------------------------------\nRan 13 tests in 0.001s\n\nOK\n",
    "attempts": 2,
    "successful_attempt": 2,
    "score_weight": 0.6
  },
  {
    "id": "str_004",
    "category": "string_processing",
    "difficulty": "hard",
    "title": "Template Engine",
    "passed": true,
    "error": null,
    "generated_code": "import re\n\ndef template_engine(template: str, context: dict) -> str:\n    \"\"\"\n    Implement a simple template engine that replaces placeholders with values.\n\n    Placeholders are enclosed in double curly braces: {{key}}\n\n    Features:\n    - Simple replacement: {{name}} is replaced with context['name']\n    - Nested access: {{user.name}} accesses context['user']['name']\n    - Default values: {{key|default}} uses 'default' if key is missing\n    - If a key is not found and no default is given, leave the placeholder as-is\n    - Strip whitespace inside braces: {{ name }} is the same as {{name}}\n    - Values are converted to strings using str()\n\n    Args:\n        template: A string with {{placeholder}} markers\n        context: A dictionary of values for substitution\n\n    Returns:\n        The template string with placeholders replaced\n\n    Examples:\n        template_engine('Hello {{name}}!', {'name': 'World'})\n        -> 'Hello World!'\n\n        template_engine('{{user.name}} is {{user.age}}',\n                        {'user': {'name': 'Alice', 'age': 30}})\n        -> 'Alice is 30'\n\n        template_engine('{{missing|default_val}}', {})\n        -> 'default_val'\n\n        template_engine('{{missing}}', {})\n        -> '{{missing}}'\n    \"\"\"\n    def replace_placeholder(match):\n        # Get the content inside {{ }}\n        content = match.group(1)\n        \n        # Strip whitespace\n        content = content.strip()\n        \n        # Check for default value\n        default_value = None\n        if '|' in content:\n            parts = content.split('|', 1)\n            key_part = parts[0].strip()\n            default_value = parts[1].strip()\n        else:\n            key_part = content\n        \n        # Handle empty key - return original placeholder\n        if not key_part:\n            return match.group(0)\n        \n        # Try to get the value from context\n        try:\n            # Handle nested access\n            keys = key_part.split('.')\n            value = context\n            for key in keys:\n                value = value[key]\n            return str(value)\n        except (KeyError, TypeError, IndexError):\n            # Key not found\n            if default_value is not None:\n                return default_value\n            else:\n                # Return original placeholder if no default\n                return match.group(0)\n    \n    # Use regex to find all {{...}} patterns (non-greedy to handle multiple placeholders)\n    result = re.sub(r'\\{\\{(.+?)\\}\\}', replace_placeholder, template)\n    return result",
    "stdout": "",
    "stderr": ".................\n----------------------------------------------------------------------\nRan 17 tests in 0.001s\n\nOK\n",
    "attempts": 1,
    "successful_attempt": 1,
    "score_weight": 1.0
  }
]